# 跟单交易系统：扩容与成本评估报告

要支持“大量用户”（如万人级别）进行稳定可靠的毫秒级跟单，单纯的代码优化已经不够，必须升级到底层架构和基础设施层面。

以下是针对不同用户量级的服务器配置、RPC 成本预估及高可用方案建议。

---

## 1. 核心瓶颈分析

在现有的 Supervisor 架构中，随着用户量增加，主要瓶颈会依次出现在以下三个环节：

1.  **RPC 请求爆发 (RPC Burst)**：
    *   **场景**：当一个热门交易员开单，假如有 5,000 人跟单。
    *   **瞬间压力**：系统需要在 **几百毫秒内** 发出 5,000 笔 `EstimateGas`（估算 Gas）和 5,000 笔 `SendTransaction`（发送交易）。
    *   **后果**：普通的 RPC 节点（如 Alchemy 免费版/基础版）会直接触发 Rate Limit（速率限制），导致 90% 的跟单失败。

2.  **Node.js 事件循环阻塞**：
    *   **场景**：目前的 `copy-trading-supervisor.ts` 是单进程运行。遍历 5,000 个用户配置并计算仓位是 CPU 密集型操作。
    *   **后果**：处理延迟会从 10ms 增加到 2s+，导致“滑点”过大，跟单价格极差。

3.  **Fleet Wallet（打手钱包）Nonce 冲突**：
    *   **场景**：目前有 20 个打手钱包。如果 5,000 笔交易挤在 20 个钱包里发出，每个钱包队列长度为 250。
    *   **后果**：Polygon 的区块时间是 ~2秒。如果一个钱包的一笔交易卡住（Nonce Gap），后面 249 笔全部无法上链。

---

## 2. 推荐服务器架构方案

我们按照三个阶段来规划：

### 阶段一：起步期（100 - 1,000 用户）
*目标：低成本，快速验证，单机架构。*

*   **应用服务器**：
    *   **配置**：4 vCPU / 8GB RAM (如 AWS t3.large 或 DigitalOcean Droplet)。
    *   **架构**：PM2 运行 2-4 个 Supervisor 实例（利用多核）。
*   **数据库**：
    *   Managed PostgreSQL (如 AWS RDS t3.medium)，连接数设为 200+。
    *   需要 **PgBouncer** 进行连接池管理。
*   **RPC 节点**：
    *   **供应商**：Alchemy 或 QuickNode 的 "Growth" 套餐。
    *   **成本**：约 **$49 - $100 / 月**。

### 阶段二：高速发展期（1,000 - 10,000 用户）
*目标：高性能，读写分离，Redis 队列。*

*   **应用服务器**：
    *   **配置**：**集群模式**。2台 8 vCPU / 16GB RAM 服务器。
    *   **架构改造**：必须要引入 **Redis**。
        *   `Detector`（检测者）：1个实例，只负责听链，将信号推送到 Redis Pub/Sub。
        *   `Executor`（执行者）：N 个实例，从 Redis 抢任务并行执行。
*   **数据库**：
    *   生产级 RDS (m5.large)，开启读写分离。
*   **Fleet Wallet**：
    *   扩容到 **50 - 100** 个打手钱包，减少单钱包排队压力。
*   **RPC 节点**：
    *   **供应商**：QuickNode "Scale" 或 Alchemy "Scale"。需要购买额外的 Compute Units (CU)。
    *   **成本**：约 **$300 - $800 / 月**。

### 阶段三：海量并发（10,000+ 用户）
*目标：金融级稳定，毫秒级响应，私有节点。*

*   **基础设施**：
    *   Kubernetes (K8s) 自动扩容。
*   **RPC 节点（关键）**：
    *   此时购买第三方 RPC 极贵且有延迟。
    *   **建议方案**：**自建节点**。购买高性能裸金属服务器（如 EPYC 处理器，4TB NVMe SSD），运行 Erigon 或 Reth 客户端同步 Polygon 节点。
    *   **成本**：服务器租赁约 **$300 - $500 / 月**（比买 RPC 服务便宜且快得多）。
*   **Flashbots / FastLane**：
    *   接入 Polygon 的私有交易池（Private Mempool），绕过公共 Mempool，避免 Gas War 和被抢跑。

---

## 3. 付费 RPC 费用详细评估

假设模型：
*   **日活跟单用户**：2,000 人
*   **日均交易次数**：跟单 10 次/人 = 20,000 笔交易/天
*   **RPC 消耗**：每笔交易消耗约 3,000 CUs (Call + EstimateGas + Send + Receipt)。

**每日消耗**：20,000 * 3,000 = 60,000,000 (6000万) CUs。
**每月消耗**：~18亿 CUs。

**主流供应商比价**：

| 供应商 | 套餐建议 | 月费预估 | 优势 | 劣势 |
| :--- | :--- | :--- | :--- | :--- |
| **Alchemy** | Scale Tier | **$500 - $800** | 极其稳定，调试工具好 | 价格较贵，Polygon 上有时候会有延迟 |
| **QuickNode** | Scale | **$300 - $600** | Polygon 节点响应极快 (Global Edge) | 计费模式复杂 |
| **Drpc.org** | Pay-as-you-go | **$100 - $200** | 聚合器，价格最便宜 | 稳定性不如单一大厂，适合做备用 |
| **自建节点** | 裸金属服务器 | **$200 + 运维人工** | **0 延迟，无限制** | 需要专业运维知识，节点同步慢 |

**💡 建议策略**：
初期使用 **QuickNode** (速度快)，配合 **Drpc.org** (价格低) 作为 Failover（故障转移）备用。

---

## 4. 如何做到“稳定可靠”？（高可用 checklist）

仅仅花钱买服务器是不够的，代码和架构必须跟上：

1.  **多 RPC 故障转移 (RPC Failover)**：
    *   **现状**：代码里只配置了一个 `RPC_URL`。
    *   **改进**：在 `ethers.js` 层封装一个 `FailoverProvider`。配置 3 个 RPC（主用 Alchemy，备用 Infura，兜底 Drpc）。如果主节点超时，自动切换备用，这对防“漏单”至关重要。

2.  **Redis 持久化队列**：
    *   **现状**：`jobQueue` 是内存数组。如果服务器重启，所有待执行的跟单都会丢失。
    *   **改进**：使用 Redis List (`rpush`/`lpop`)。即使进程崩溃，重启后依然能从 Redis 恢复未完成的交易。

3.  **打手钱包监控 (Stuck Tx Monitor)**：
    *   **风险**：Polygon 链有时候会 Gas 暴涨，导致交易“卡死” (Pending) 数小时。
    *   **方案**：开发一个监控脚本，每分钟检查所有 Fleet Wallet。如果发现有 Pending > 1分钟的交易，立即以 2倍 Gas 发送一笔由相同 Nonce 的“覆盖交易” (Speed Up) 来疏通队列。

4.  **数据库连接池 (PgBouncer)**：
    *   Node.js 保持长连接的能力有限。在并发高时，必须在 Postgres 前面加一层 PgBouncer，否则数据库会报 `Too many connections` 错误。

## 总结

对于目前的阶段，我建议：

1.  **服务器**：升级到 **8GB 内存** 实例。
2.  **RPC**：购买 **QuickNode Growth ($49)** 或 **Scale ($299)** 套餐，确保每秒请求数 (RPS) 至少支持 100+。
3.  **代码改进**：
    *   引入 Redis 替代内存队列。
    *   实现 RPC 轮询/故障切换机制。
    *   增加“卡单自动加速”逻辑。
